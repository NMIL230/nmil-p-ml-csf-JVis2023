{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba93d1a3",
   "metadata": {},
   "source": [
    "# Figure 4: Random sampling on 4 canonical CSF phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1c9cd",
   "metadata": {},
   "source": [
    "## Manuscript Information\n",
    " \n",
    "\"Contrast Response Function Estimation with Nonparametric Bayesian Active Learning\"  \n",
    "_Journal of Vision_\n",
    "https://www.medrxiv.org/content/10.1101/2023.05.11.23289869v2\n",
    "\n",
    "## Lab and Institution Information\n",
    "\n",
    "NeuroMedical Informatics Lab  \n",
    "Washington University in St. Louis\n",
    "\n",
    "## Figure Description\n",
    "\n",
    "Display the four canonical phenotype Contrast Sensitivity Function (CSF) curves used to construct the generative models of Experiment 1. For each phenotype, train a GP from randomly sampled points labeled according to the generative model for that phenotype.\n",
    "\n",
    "## References\n",
    "\n",
    "Kalloniatis, Michael, and Charles Luu. “Visual Acuity.” In _Webvision: The Organization of the Retina and Visual System_, edited by Helga Kolb, Eduardo Fernandez, and Ralph Nelson. Salt Lake City (UT): University of Utah Health Sciences Center, 1995. http://www.ncbi.nlm.nih.gov/books/NBK11509/.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717588b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import sys\n",
    "import torch as pt\n",
    "import gpytorch as gp\n",
    "from utility.utils import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945831c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"python version -->>\", sys.version)\n",
    "print(\"pytorch version -->>\", pt.__version__)\n",
    "print(\"gpytorch version -->>\", gp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b454df3",
   "metadata": {},
   "source": [
    "This code was written for\n",
    "\n",
    "- python version 3.10.9\n",
    "- pytorch version 1.13.1\n",
    "- gpytorch version 1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ba676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-time flags\n",
    "\n",
    "verb_mode = True           # print verbose analyses?\n",
    "scrn_mode = True           # plot on screen?\n",
    "save_mode = True           # save plots in indicated directory?\n",
    "\n",
    "plot_canon = True          # plot canonical CSF spline-interpolated curves?\n",
    "plot_prior  = True         # plot GP posterior mean as prior?\n",
    "plot_thresh  = True        # plot 50% threshold curve of prior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant declarations\n",
    "\n",
    "# Fix random seed\n",
    "generative_random_seed = 1\n",
    "\n",
    "# evaluation grid bounds in raw linear units\n",
    "raw_freq_min = 1         # cycles per degree\n",
    "raw_freq_max = 64        # cycles per degree\n",
    "raw_contrast_min = 1e-3  # contrast\n",
    "raw_contrast_max = 1     # contrast\n",
    "\n",
    "# marginal log resolutions of evaulation grid\n",
    "x_resolution = 15  # 15 spatial frequencies per octave\n",
    "y_resolution = 30  # 30 contrast units per decade\n",
    "\n",
    "# for computing the proper prior threshold curve\n",
    "psi_gamma  = 0.04  # guess rate is 4%\n",
    "psi_lambda = 0.04  # lapse rate is 4%\n",
    "psi_sigma = .08\n",
    "sigmoid_type = 'logistic'\n",
    "\n",
    "# training parameters?\n",
    "num_halton_points = 8\n",
    "num_initial_points_training_iters = 500\n",
    "num_new_points = 92\n",
    "num_new_points_training_iters = 150\n",
    "\n",
    "# GP hyperparameters?\n",
    "lr = .125\n",
    "beta_for_regularization = 0.25\n",
    "gaussian_lengthscale = None\n",
    "min_lengthscale = .15 \n",
    "\n",
    "# other\n",
    "prior_raw_freq_min = 0.5\n",
    "prior_raw_freq_max = 64\n",
    "prior_raw_contrast_min = 1e-3\n",
    "prior_raw_contrast_max = 1\n",
    "\n",
    "random_seed = 1\n",
    "\n",
    "\n",
    "# define ghost points (they will have a label of 0, i.e., a color of red)\n",
    "raw_freq_ghost_points = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "raw_contrast_ghost_points = [5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 1]\n",
    "\n",
    "# other params to train_and_sample_gp method\n",
    "train_on_all_points_after_sampling = False\n",
    "calculate_rmse = True\n",
    "calculate_entropy = True\n",
    "calculate_posterior = True\n",
    "\n",
    "markerwidth = .8\n",
    "marker_size = 60\n",
    "success_marker = '+' \n",
    "diamond_size = 1.0\n",
    "diamond_width = .076            # specified in cycles per degree\n",
    "diamond_height = .10            # specified in log10(contrast)\n",
    "success_color = 'blue'\n",
    "failure_color = 'red'\n",
    "latent_color = '#cf30cf'\n",
    "mean_color = '#40E1D0'\n",
    "diamond_fill_color = 'None'\n",
    "success_label = 'success'\n",
    "failure_label = 'failure'\n",
    "\n",
    "rmse_filename = 'rmses'\n",
    "\n",
    "plot_points = True\n",
    "\n",
    "cax_location_params = [0.84, 0.1, 0.02, 0.8] # [left, bottom, width, height]\n",
    "\n",
    "subplots_adjust_params = {\n",
    "    'bottom':0.1, \n",
    "    'top':0.9, \n",
    "    'left':0.1, \n",
    "    'right':0.8, \n",
    "    'wspace':0.05, \n",
    "    'hspace':0.3\n",
    "}\n",
    "\n",
    "num_rows = 2\n",
    "num_cols = 2\n",
    "\n",
    "data_dir = 'data/raw_data/'\n",
    "data_file_name = 'csf_curves_exp1.json'\n",
    "data_file_path = f'{data_dir}{data_file_name}'\n",
    "\n",
    "csf_curves_exp1 = load_json_from_file(data_file_path)\n",
    "\n",
    "phenotypes = [\n",
    "    ('Normal', csf_curves_exp1['normal']),\n",
    "    ('Mild Amblyopia', csf_curves_exp1['mild_amblyopia']),\n",
    "    ('Cataracts', csf_curves_exp1['cataracts']),\n",
    "    ('Multiple Sclerosis', csf_curves_exp1['multiple_sclerosis'])\n",
    "]\n",
    "\n",
    "if verb_mode:\n",
    "    print_training_iters = True\n",
    "    print_training_hyperparameters = False\n",
    "    progress_bar = False\n",
    "else:\n",
    "    print_training_iters = False\n",
    "    print_training_hyperparameters = False\n",
    "    progress_bar = False\n",
    "    \n",
    "cblab_loc = 'center'\n",
    "\n",
    "axis_tick_params = {\n",
    "    'axis':'both', \n",
    "    'which':'major', \n",
    "    'direction':'out'\n",
    "}\n",
    "\n",
    "mean_module_name = 'constant_mean'\n",
    "\n",
    "# end other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef97abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard plotting parameters\n",
    "\n",
    "fig_width = 8     # inches\n",
    "fig_height = 4  # inches\n",
    "\n",
    "dpi_val = 600     # graphics resolution\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "legend_font_size = 8\n",
    "legend_font_weight = 'roman'\n",
    "tick_font_size = 10\n",
    "tick_font_weight = 'roman'\n",
    "label_font_size = 12\n",
    "label_font_weight = 'roman'\n",
    "title_font_size = 14\n",
    "title_font_weight = 'roman'\n",
    "suptitle_font_size = 16\n",
    "suptitle_font_weight = 'roman'\n",
    "\n",
    "colors = sns.color_palette('colorblind', n_colors=12)  # colorblind friendly palette\n",
    "col1=0; col2=1; col3=2; col4=4\n",
    "\n",
    "\n",
    "x_tick_labels = [1, 4, 16, 64]\n",
    "x_tick_values = logFreq().forward(np.array(x_tick_labels))\n",
    "y_tick_labels = [1, 0.1, 0.01, 0.001]\n",
    "y_tick_values = logContrast().forward(np.array(y_tick_labels))\n",
    "cb_tick_labels = [0, 0.25, 0.5, 0.75, 1]\n",
    "cb_tick_values = cb_tick_labels\n",
    "\n",
    "cb_pad = 0.05  # move coloarbar xx units horizontally\n",
    "cblab_pad = -53  # move colorbar label xx units horizontally\n",
    "\n",
    "num_spline_vals = 750  # number of interpolated points in spline curves\n",
    "\n",
    "colmap='gist_gray'\n",
    "\n",
    "# Plotting order -- higher on top\n",
    "success_zorder = 5\n",
    "fail_zorder = 4\n",
    "thresh_zorder = 3\n",
    "canon_zorder = 2\n",
    "posterior_zorder = 1\n",
    "\n",
    "p_title = 'Human Contrast Sensitivity Phenotypes'\n",
    "x_label = 'Spatial Frequency (cyc/deg)'\n",
    "y_label = 'Contrast'\n",
    "cb_label = 'Detection Probability'\n",
    "\n",
    "save_dir = './analysis/figure_04/'\n",
    "file_stem = 'Figure04_RandomSampling'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c459dde",
   "metadata": {},
   "source": [
    "## Perform analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36444c13",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "set_random_seed(random_seed)\n",
    "\n",
    "for i in range(len(phenotypes)):\n",
    "    title, curve = phenotypes[i]\n",
    "\n",
    "    ###################\n",
    "    # CONSTRUCT CURVE #\n",
    "    ###################\n",
    "\n",
    "    curve = np.array(curve)\n",
    "    # prepare freqs - turn log10 to log2, and start from 0\n",
    "    curve[:, 0] = (np.log2(10) * curve[:, 0]) - np.log2(.125)\n",
    "    left, right, bottom, top = get_data_bounds(curve)\n",
    "\n",
    "    cs = create_cubic_spline(curve)\n",
    "\n",
    "    ###############\n",
    "    # CREATE GRID #\n",
    "    ###############\n",
    "\n",
    "    # Transform these bounds - used to make grid\n",
    "    x_min = logFreq().forward(raw_freq_min)\n",
    "    x_max = logFreq().forward(raw_freq_max)\n",
    "    y_min = logContrast().forward(raw_contrast_max)  # max and min get flipped when inverting\n",
    "    y_max = logContrast().forward(raw_contrast_min)\n",
    "\n",
    "    # Make grid\n",
    "    grid, xx, yy, xs, ys = create_evaluation_grid_resolution(x_min, x_max, y_min, y_max, \\\n",
    "                                                             x_resolution, y_resolution)\n",
    "\n",
    "    #################\n",
    "    # GENERATE DATA #\n",
    "    #################\n",
    "\n",
    "    # define how to transform the data\n",
    "    prior_freq_min = logFreq().forward(prior_raw_freq_min)\n",
    "    prior_freq_max = logFreq().forward(prior_raw_freq_max)\n",
    "    prior_contrast_min = logContrast().forward(prior_raw_contrast_max) # 1/x swaps min and max\n",
    "    prior_contrast_max = logContrast().forward(prior_raw_contrast_min)\n",
    "    \n",
    "    def f(d):\n",
    "        return scale_data_within_range(d, (0, 1), prior_freq_min, \\\n",
    "                                       prior_freq_max, prior_contrast_min, prior_contrast_max)\n",
    "\n",
    "    # create ghost points\n",
    "    ghost_x1 = logFreq().forward(np.array(raw_freq_ghost_points))\n",
    "    ghost_x2 = logContrast().forward(np.array(raw_contrast_ghost_points))\n",
    "    \n",
    "    assert len(ghost_x1) == len(ghost_x2), \"make sure that the ghost arrays have the same length\"\n",
    "\n",
    "    ghost_X = np.vstack((ghost_x1, ghost_x2)).T\n",
    "    ghost_y = np.array([0]*len(ghost_x2))\n",
    "\n",
    "    num_ghost_points = len(ghost_y)\n",
    "\n",
    "    # create initial data points\n",
    "    halton_X, halton_y = halton_samples_from_data(xx, yy, cs, \\\n",
    "        psi_gamma, psi_lambda, num_halton_points, sigmoid_type = sigmoid_type, psi_sigma = psi_sigma)\n",
    "\n",
    "    initial_Xs = np.vstack((ghost_X, halton_X))\n",
    "    initial_ys = np.hstack((ghost_y, halton_y))\n",
    "\n",
    "    num_initial_points = len(initial_ys) \n",
    "\n",
    "    # transform the data\n",
    "    def f(d):\n",
    "        return scale_data_within_range(d, (0, 1), x_min, x_max, y_min, y_max)\n",
    "\n",
    "    #####################\n",
    "    # INIT AND TRAIN GP #\n",
    "    #####################\n",
    "    \n",
    "    model, likelihood, X, y, rmse_list, posterior_list, _ = sample_and_train_gp(\n",
    "        cs,\n",
    "        grid,\n",
    "        xx,\n",
    "        yy,\n",
    "        sampling_strategy='random',\n",
    "        mean_module_name=mean_module_name,\n",
    "        psi_sigma=psi_sigma,\n",
    "        sigmoid_type=sigmoid_type,\n",
    "        psi_gamma=psi_gamma,\n",
    "        psi_lambda=psi_lambda,\n",
    "        lr=lr,\n",
    "        num_initial_training_iters=num_initial_points_training_iters,\n",
    "        num_new_points_training_iters=num_new_points_training_iters,\n",
    "        num_new_points=num_new_points,\n",
    "        beta_for_regularization=beta_for_regularization,\n",
    "        train_on_all_points_after_sampling=train_on_all_points_after_sampling,\n",
    "        phi=f,\n",
    "        print_training_hyperparameters=print_training_hyperparameters,\n",
    "        print_training_iters=print_training_iters,\n",
    "        progress_bar=progress_bar,\n",
    "        min_lengthscale=min_lengthscale,\n",
    "        calculate_rmse=calculate_rmse,\n",
    "        calculate_entropy=calculate_entropy,\n",
    "        calculate_posterior=calculate_posterior,\n",
    "        initial_Xs=initial_Xs,\n",
    "        initial_ys=initial_ys,\n",
    "        num_ghost_points=num_ghost_points\n",
    "    )\n",
    "    \n",
    "    #################\n",
    "    # EVALUATE GRID #\n",
    "    #################\n",
    "\n",
    "    # transform evaluation grid so it can be used by GP\n",
    "    grid_transformed = transform_dataset(grid, phi=f)\n",
    "\n",
    "    # get the predictions on the eval grid\n",
    "    Z = evaluate_posterior_mean(model, likelihood, grid_transformed)\n",
    "    zz = Z.reshape(xx.shape)\n",
    "    \n",
    "    \n",
    "    results[i] = {\n",
    "        'xx': xx,\n",
    "        'yy': yy,\n",
    "        'zz': zz,\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'left': left,\n",
    "        'right': right,\n",
    "        'top': top,\n",
    "        'bottom': bottom,\n",
    "        'cs': cs,\n",
    "        'psi_sigma': psi_sigma,\n",
    "        'sigmoid_type': sigmoid_type,\n",
    "        'psi_gamma': psi_gamma,\n",
    "        'psi_lambda': psi_lambda,\n",
    "        'x_min': x_min,\n",
    "        'x_max': x_max,\n",
    "        'y_min': y_min,\n",
    "        'y_max': y_max,\n",
    "        'xs': xs,\n",
    "        'ys': ys,\n",
    "        'initial_points': num_initial_points,\n",
    "        'grid': grid,\n",
    "        'model': model,\n",
    "        'likelihood': likelihood,\n",
    "        'f': f,\n",
    "        'rmse': rmse_list,\n",
    "        'posterior_list': posterior_list,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec8ce2",
   "metadata": {},
   "source": [
    "## Plot figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55425aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The \"results\" dict has all of the information from the GP training.\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "plt.tight_layout()\n",
    "\n",
    "# Set figure size\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(fig_width, fig_height), dpi=dpi_val)\n",
    "\n",
    "rmse_values = []\n",
    "    \n",
    "for i in range(len(phenotypes)):\n",
    "    \n",
    "    ax = axs[i // num_rows, i % num_rows]\n",
    "    \n",
    "    title, _ = phenotypes[i]\n",
    "\n",
    "    pheno_results = results[i]\n",
    "    \n",
    "    xx = pheno_results['xx']\n",
    "    yy = pheno_results['yy']\n",
    "    zz = pheno_results['zz']\n",
    "    X = pheno_results['X']\n",
    "    y = pheno_results['y']\n",
    "    left = pheno_results['left']\n",
    "    right = pheno_results['right']\n",
    "    top = pheno_results['top']\n",
    "    bottom = pheno_results['bottom']\n",
    "    cs = pheno_results['cs']\n",
    "    psi_sigma = pheno_results['psi_sigma']\n",
    "    psi_gamma = pheno_results['psi_gamma']\n",
    "    psi_lambda = pheno_results['psi_lambda']\n",
    "    x_min = pheno_results['x_min']\n",
    "    x_max = pheno_results['x_max']\n",
    "    y_min = pheno_results['y_min']\n",
    "    y_max = pheno_results['y_max']\n",
    "    xs = pheno_results['xs']\n",
    "    ys = pheno_results['ys']\n",
    "    initial_points = pheno_results['initial_points']\n",
    "    grid = pheno_results['grid']\n",
    "    f = pheno_results['f']\n",
    "    posterior_list = pheno_results['posterior_list']\n",
    "    rmse_list = pheno_results['rmse']\n",
    "    \n",
    "    print(f'{title}:', rmse_list[-1])\n",
    "    rmse = rmse_list[-1]\n",
    "    \n",
    "    rmse_values.append(f'{title}: ' + str(rmse_list[-1]))\n",
    "    \n",
    "    ############\n",
    "    # PLOTTING #\n",
    "    ############\n",
    "\n",
    "    # plot the contour field\n",
    "    if plot_prior:\n",
    "        mesh = ax.pcolormesh(xx, yy, zz, cmap=colmap, vmin=0, vmax=1, zorder=posterior_zorder)\n",
    "        cax = fig.add_axes(cax_location_params)\n",
    "        cbar = fig.colorbar(mesh, cax=cax, ticks=cb_tick_values, format='%g')\n",
    "        cbar.set_label(cb_label, loc=cblab_loc, labelpad=cblab_pad)\n",
    "\n",
    "    if plot_points:\n",
    "        x1_failure = X[y == 0, 0].reshape(-1)\n",
    "        x2_failure = X[y == 0, 1].reshape(-1)\n",
    "        x1_success = X[y == 1, 0].reshape(-1)\n",
    "        x2_success = X[y == 1, 1].reshape(-1)\n",
    "\n",
    "        # Create diamond corner array\n",
    "        diamond_corners = np.array([\n",
    "                                  [x1_failure, x2_failure + diamond_height*diamond_size],\n",
    "                                  [x1_failure + diamond_width*diamond_size, x2_failure],\n",
    "                                  [x1_failure, x2_failure - diamond_height*diamond_size],\n",
    "                                  [x1_failure - diamond_width*diamond_size, x2_failure]])\n",
    "        ax.scatter(x1_success, x2_success, marker =success_marker, s=marker_size, color=success_color,\n",
    "                     zorder=success_zorder, linewidth=markerwidth, label=success_label)\n",
    "        ax.fill(diamond_corners[:, 0], diamond_corners[:, 1], color= diamond_fill_color, \\\n",
    "                edgecolor=failure_color, \n",
    "                  zorder= fail_zorder, linewidth=markerwidth, label = failure_label)\n",
    "  \n",
    "    # plot the spline\n",
    "    if plot_canon:\n",
    "        latent_x1 = np.linspace(left, right, num_spline_vals)\n",
    "        latent_x2 = cs(latent_x1)\n",
    "        ax.plot(latent_x1, latent_x2, color=latent_color, zorder=canon_zorder)\n",
    "\n",
    "    # plot the level curve\n",
    "    if plot_thresh:\n",
    "        level = (1 - psi_lambda + psi_gamma) / 2\n",
    "        ax.contour(xx, yy, zz, levels=[level], colors=[mean_color], \\\n",
    "                   linestyles=['dashed'], zorder=thresh_zorder)\n",
    "    \n",
    "    ax.set_title(title, fontdict={'fontsize': title_font_size})\n",
    "    \n",
    "    # lims\n",
    "    x_padding = (x_max - x_min) / (2 * (xs - 1))\n",
    "    y_padding = (y_max - y_min) / (2 * (ys - 1))\n",
    "    ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "    ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "    \n",
    "# set ticks and title\n",
    "plt.setp(axs, xticks=x_tick_values, xticklabels=x_tick_labels, yticks=y_tick_values, yticklabels=y_tick_labels)\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel=x_label, ylabel=y_label)\n",
    "    ax.label_outer() # only include across left and bottom\n",
    "    ax.tick_params(**axis_tick_params, labelsize=tick_font_size)\n",
    "\n",
    "# adjust and create colorbar\n",
    "fig.subplots_adjust(**subplots_adjust_params)\n",
    "\n",
    "if save_mode:\n",
    "    ensure_directory_exists(save_dir)\n",
    "    plt.savefig(f'{save_dir}{file_stem}.png', bbox_inches='tight', dpi=dpi_val)\n",
    "    plt.savefig(f'{save_dir}{file_stem}.pdf', bbox_inches='tight', dpi=dpi_val)\n",
    "    with open(f'{save_dir}{rmse_filename}.txt', 'w') as file:\n",
    "        for string in rmse_values:\n",
    "            file.write(string + '\\n')\n",
    "            \n",
    "if scrn_mode:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1016e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
