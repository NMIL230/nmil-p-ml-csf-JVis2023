{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba93d1a3",
   "metadata": {},
   "source": [
    "# Figure 7: Plot ground truth schizophrenia participant 1 and 100 points active learning fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f497820",
   "metadata": {},
   "source": [
    "## Manuscript Information\n",
    " \n",
    "\"Contrast Response Function Estimation with Nonparametric Bayesian Active Learning\"  \n",
    "_Journal of Vision_\n",
    "https://www.medrxiv.org/content/10.1101/2023.05.11.23289869v2\n",
    "\n",
    "## Lab and Institution Information\n",
    "\n",
    "NeuroMedical Informatics Lab  \n",
    "Washington University in St. Louis\n",
    "\n",
    "## Figure Description\n",
    "\n",
    "Display Contrast Sensitivity Function (CSF) curve of subject SP1 used in Experiment 2. Train 100 iterations of Gaussian Process machine learning with active learning stimulus selection on simulated data to calculate a Contrast Response Function (CRF).\n",
    "\n",
    "## References\n",
    "\n",
    "Yaghoubi, K. C., Jayakumar, S., Ahmed, A. O., Butler, P. D., Silverstein, S., Thompson, J. L., & Seitz, A. R. (2022). Characterization of training profiles between individuals with schizophrenia and healthy individuals on Contrast Detection and Contour Integration tasks. Journal of Vision, 22(14), 3728â€“3728. https://jov.arvojournals.org/article.aspx?articleid=2784727&resultClick=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717588b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utility.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import gpytorch as gp\n",
    "import torch as pt\n",
    "import sys\n",
    "import seaborn as sns  # statistical plotting library\n",
    "import json\n",
    "import datetime\n",
    "from matplotlib.gridspec import GridSpec  # Import GridSpec\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f52771e",
   "metadata": {},
   "source": [
    "Check versions of python, Gpytorch, and Pytorch dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945831c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"python version -->>\", sys.version)\n",
    "print(\"gpytorch version -->>\", gp.__version__)\n",
    "print(\"pytorch version -->>\", pt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f766a4",
   "metadata": {},
   "source": [
    "This code was written for\n",
    "\n",
    "- python version 3.10.9\n",
    "- pytorch version 1.13.1\n",
    "- gpytorch version 1.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9e137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run-time flags\n",
    "\n",
    "verb_mode = False           # print verbose analyses?\n",
    "scrn_mode = True          # plot on screen?\n",
    "save_mode = True           # save plots in indicated directory?\n",
    "\n",
    "\n",
    "# Fig A\n",
    "plot_a_canon = True         # plot canonical CSF spline-interpolated curves?\n",
    "plot_a_prior  = True        # plot GP posterior mean?\n",
    "plot_a_thresh  = True        # plot 50% threshold curve of GP posterior mean?\n",
    "plot_a_data = True           # plot actively learned data?\n",
    "\n",
    "# Fig B\n",
    "plot_b_rmse = True           # plot Root Mean Square Error of GP CSF estimation?\n",
    "plot_b_canon = True          # plot canonical CSF spline-interpolated curves?\n",
    "plot_b_thresh = True         # plot 50% threshold curve of prior?\n",
    "\n",
    "# Fig C\n",
    "plot_c_cdf = True            # plot the Cumulative Density Function \n",
    "plot_c_canonical = True\n",
    "# Choose the raw frequency for Figure C\n",
    "raw_freq_to_slice_at = 4     # cycles per degree\n",
    "freq_to_slice_at = logFreq().forward(raw_freq_to_slice_at)\n",
    "\n",
    "# dir to save to\n",
    "save_dir = 'analysis/figure_07/'\n",
    "\n",
    "# Save RMSE to text file\n",
    "save_rmse = True\n",
    "rmse_txt_path = f'{save_dir}rmses.txt'\n",
    "\n",
    "# Individual print flags \n",
    "print_training_hyperparameters = False \n",
    "print_training_iters = False\n",
    "print_progress_bar = False\n",
    "\n",
    "# Set all to true if Verbmode\n",
    "if verb_mode:\n",
    "    print_training_hyperparameters = True\n",
    "    print_training_iters = True\n",
    "    print_progress_bar = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant Declarations\n",
    "\n",
    "data_dir = 'data/raw_data/'\n",
    "data_file_name = 'csf_curves_exp2.json'\n",
    "data_file_path = f'{data_dir}{data_file_name}'\n",
    "\n",
    "csf_curves_exp2 = load_json_from_file(data_file_path)\n",
    "\n",
    "# Which phenotypes are you considering?\n",
    "# This code must be updated once we decide on data storage (JSON) loading and \n",
    "# dict for non-index acces vs list for simplicity\n",
    "phenos = [('SZ1', csf_curves_exp2['schizophrenia_participants'][1])]\n",
    "\n",
    "# random seed\n",
    "generative_random_seed = 2\n",
    "\n",
    "# Prior raw bounds\n",
    "prior_raw_freq_min = 0.5\n",
    "prior_raw_freq_max = 64\n",
    "prior_raw_contrast_min = 1e-3\n",
    "prior_raw_contrast_max = 1\n",
    "\n",
    "# Prior bounds\n",
    "prior_freq_min = logFreq().forward(prior_raw_freq_min)\n",
    "prior_freq_max = logFreq().forward(prior_raw_freq_max)\n",
    "prior_contrast_sensitivity_min = logContrast().forward(prior_raw_contrast_max)  # max and min get flipped when inverting\n",
    "prior_contrast_sensitivity_max = logContrast().forward(prior_raw_contrast_min)\n",
    "\n",
    "# Create the bounds for the data\n",
    "raw_freq_min = 0.5\n",
    "raw_freq_max = 32\n",
    "raw_contrast_min = 1e-3\n",
    "raw_contrast_max = 1\n",
    "\n",
    "# Define how to transform the data\n",
    "x_min = logFreq().forward(raw_freq_min)\n",
    "x_max = logFreq().forward(raw_freq_max)\n",
    "y_min = logContrast().forward(raw_contrast_max)  # max and min get flipped when inverting\n",
    "y_max = logContrast().forward(raw_contrast_min)\n",
    "\n",
    "# transform the data\n",
    "def normalize_to_unit_range(d):\n",
    "    return scale_data_within_range(d, (0, 1), prior_freq_min, prior_freq_max, prior_contrast_sensitivity_min, prior_contrast_sensitivity_max)\n",
    "\n",
    "# marginal log resolutions of evaulation grid\n",
    "x_resolution = 15  # 15 spatial frequencies per octave\n",
    "y_resolution = 30  # 30 contrast units per decade\n",
    "\n",
    "# for computing the proper prior threshold curve\n",
    "psi_gamma  = 0.04  # guess rate is 4%\n",
    "psi_lambda = 0.04  # lapse rate is 4%\n",
    "psi_sigma = .08\n",
    "sigmoid_type = 'logistic'\n",
    "\n",
    "# training parameters?\n",
    "num_halton_samples = 8\n",
    "num_initial_points_training_iters = 500\n",
    "num_new_points = 92\n",
    "num_new_points_training_iters = 150\n",
    "sampling_strategy = 'active'\n",
    "mean_module = 'constant_mean'\n",
    "train_on_all_points_after_sampling = False\n",
    "calculate_posterior = True\n",
    "calculate_entropy = True\n",
    "\n",
    "# Set raw ghost points \n",
    "raw_ghost_frequency = np.array([0.5, 1, 2, 4, 8, 16, 32, 64, 128, 128])\n",
    "raw_ghost_contrast = np.array([5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 5e-4, 1])\n",
    "\n",
    "# GP hyperparameters?\n",
    "learning_rate = .125\n",
    "beta_for_regularization = .25\n",
    "min_lengthscale = .15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Parameters\n",
    "\n",
    "###########\n",
    "# GENERAL #\n",
    "###########\n",
    "\n",
    "dpival = 600              # graphics resolution\n",
    "\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# size is 9 by 7 inches, Figure B and Figure C are 3 by 3 inches.\n",
    "fig_a_size = (9, 7)\n",
    "fig_b_size = (3,3)\n",
    "fig_c_size = (3,3)\n",
    "\n",
    "# Composite figure size and configuration\n",
    "figure_width = 13\n",
    "figure_height = 6\n",
    "num_plot_rows = 5\n",
    "num_plot_columns = 2\n",
    "\n",
    "legend_font_size = 8\n",
    "legend_font_weight = 'roman'\n",
    "tick_font_size = 10\n",
    "tick_font_weight = 'roman'\n",
    "label_font_size = 12\n",
    "label_font_weight = 'roman'\n",
    "title_font_size = 14\n",
    "title_font_weight = 'roman'\n",
    "suptitle_font_size = 16\n",
    "suptitle_font_weight = 'roman'\n",
    "\n",
    "# tick settings\n",
    "axis_tick_params = {\n",
    "    'axis':'both', \n",
    "    'which':'major', \n",
    "    'direction':'out'\n",
    "}\n",
    "\n",
    "# for \"A\", \"B\", \"C\" labels\n",
    "subplot_label_font_size = 16\n",
    "a_subplot_coords = (0.07, 0.89)\n",
    "b_subplot_coords = (0.56, 0.89)\n",
    "c_subplot_coords = (0.56, 0.45)\n",
    "\n",
    "##########\n",
    "# PLOT A #\n",
    "##########\n",
    "\n",
    "# plotting order -- higher on top\n",
    "success_zorder = 5\n",
    "fail_zorder = 4\n",
    "thresh_zorder = 3\n",
    "canon_zorder = 2\n",
    "posterior_zorder = 1\n",
    "\n",
    "# colors\n",
    "a_latent_color = '#cf30cf'\n",
    "a_mean_color = '#40E1D0'\n",
    "success_color = 'blue'\n",
    "failure_color = 'red'\n",
    "\n",
    "# posterior\n",
    "fig_a_cb_ticks = [0, .25, .5, .75, 1]\n",
    "fig_a_cb_labs = [str(tick) for tick in fig_a_cb_ticks]\n",
    "fig_a_cb_pad = .06\n",
    "fig_a_cb_label_pad = -55\n",
    "fig_a_cb_label = 'Detection Probability'\n",
    "a_prior_color_gradient = 'gist_gray'\n",
    "a_prior_grad_min = 0\n",
    "a_prior_grad_max = 1\n",
    "\n",
    "\n",
    "# marker dimensions\n",
    "marker_size= 60            # marker size specified in pts\n",
    "diamond_line_width = .8        # line width specified in pts\n",
    "plus_line_width= .8\n",
    "success_marker = '+'            \n",
    "diamond_size = .4               # scaling constant\n",
    "diamond_width = .152            # specified in cycles per degree\n",
    "diamond_height = .10            # specified in log10(contrast)\n",
    "diamond_fill_color = 'none'     # specify 'none' for transparent\n",
    "success_label = 'success'       \n",
    "failure_label = 'failure'\n",
    "\n",
    "# threshold\n",
    "a_linestyle= 'dashed'\n",
    "a_dash_list = [(0, (10.0, 3.0))]\n",
    "num_curve_points = 1000         # large number of points to create curve  \n",
    "\n",
    "# Figure A and B xticks and yticks\n",
    "xticks_labels = [0.5, 2, 8, 32]\n",
    "yticks_labels = [1, 0.1, 0.01, 0.001]\n",
    "xticks_values = logFreq().forward(np.array(xticks_labels))\n",
    "yticks_values = logContrast().forward(np.array(yticks_labels))\n",
    "\n",
    "# save values\n",
    "a_title  = 'SZ1'\n",
    "a_xlab = 'Spatial Frequency (cyc/deg)'\n",
    "a_ylab = 'Contrast'\n",
    "a_png_path = f\"{save_dir}Figure07_{a_title.replace(' ', '_')}.png\"\n",
    "a_pdf_path = f\"{save_dir}Figure07_{a_title.replace(' ', '_')}.pdf\"\n",
    "\n",
    "##########\n",
    "# PLOT B #\n",
    "##########\n",
    "\n",
    "# colors\n",
    "b_latent_color = 'dimgrey'\n",
    "b_mean_color = '#40E1D0'\n",
    "\n",
    "# labels\n",
    "latent_label = 'ground truth'\n",
    "mean_label = 'predicted'\n",
    "\n",
    "# dash and Legend\n",
    "b_dash_tuple = (5.5, 3)\n",
    "b_legend_location = 'lower left'\n",
    "b_dash_list = a_dash_list\n",
    "\n",
    "# rmse \n",
    "b_rmse_x_coord = 3.1\n",
    "b_rmse_y_coord = 2.8\n",
    "\n",
    "# save values\n",
    "b_title = 'Threshold'\n",
    "b_xlab = 'Spatial Frequency (cyc/deg)'\n",
    "b_ylab = 'Contrast'\n",
    "b_png_path = f\"{save_dir}Figure07_B_{b_title.replace(' ', '_')}.png\"\n",
    "b_pdf_path = f\"{save_dir}Figure07_B_{b_title.replace(' ', '_')}.pdf\"\n",
    "b_fig_pad = 0.2\n",
    "b_bbox_mode = 'tight'\n",
    "\n",
    "##########\n",
    "# PLOT C #\n",
    "##########\n",
    "\n",
    "# colors\n",
    "c_latent_color = 'dimgrey'\n",
    "c_mean_color = '#40E1D0'\n",
    "\n",
    "# dash and legend\n",
    "c_dash = 10, 3\n",
    "c_dash_symbol = '--'\n",
    "\n",
    "# labels\n",
    "c_xticks_labels = np.array([1, 0.1, 0.01, 0.001])\n",
    "c_xticks_values = logContrast().forward(c_xticks_labels)\n",
    "c_yticks_labels = ['0', '0.25', '0.5', '0.75', '1']\n",
    "c_yticks_values = np.array([0, .25, .5, .75, 1])\n",
    "\n",
    "# save values \n",
    "c_title = f'Probability at {raw_freq_to_slice_at} cyc/deg'\n",
    "c_xlab = 'Contrast'\n",
    "c_ylab = 'Detection Probability'\n",
    "c_legend_location = 'lower left'\n",
    "c_png_path = f\"{save_dir}Figure07_C_{c_title.replace(' ', '_')}.png\"\n",
    "c_pdf_path = f\"{save_dir}Figure07_C_{c_title.replace(' ', '_')}.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36444c13",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial Code executions\n",
    "\n",
    "results = dict()\n",
    "for i in range(len(phenos)):\n",
    "    title, curve = phenos[i]\n",
    "\n",
    "    ###################\n",
    "    # CONSTRUCT CURVE #\n",
    "    ###################\n",
    "    set_random_seed(generative_random_seed)\n",
    "\n",
    "    curve = np.array(curve)\n",
    "    # prepare freqs - turn log10 to log2, and start from 0\n",
    "    curve[:, 0] = (np.log2(10) * curve[:, 0]) - np.log2(.125)\n",
    "    left, right, bottom, top = get_data_bounds(curve)\n",
    "    cs = create_cubic_spline(curve)\n",
    "\n",
    "    ###############\n",
    "    # CREATE GRID #\n",
    "    ###############\n",
    "\n",
    "    # Make grid\n",
    "    grid, xx, yy, xs, ys = create_evaluation_grid_resolution(x_min, x_max, y_min, y_max, x_resolution, y_resolution)\n",
    "\n",
    "    ###################\n",
    "    # ACTIVE LEARNING #\n",
    "    ###################\n",
    "\n",
    "    # we want the grid as a tensor to pass to get_best_entropy\n",
    "\n",
    "    # create ghost points\n",
    "    ghost_x1 = logFreq().forward(raw_ghost_frequency)\n",
    "    ghost_x2 = logContrast().forward(raw_ghost_contrast)\n",
    "    assert len(ghost_x1) == len(ghost_x2), \"x1 and x2 have diff lengths\"\n",
    "\n",
    "    ghost_X = np.vstack((ghost_x1, ghost_x2)).T\n",
    "    ghost_y = np.array([0]*len(ghost_x2))\n",
    "\n",
    "    # create initial data points\n",
    "    halton_X, halton_y = halton_samples_from_data(xx, yy, cs, psi_gamma, psi_lambda, num_halton_samples, sigmoid_type = sigmoid_type, psi_sigma = psi_sigma)\n",
    "\n",
    "    # combine ghost and halton sampled points\n",
    "    initial_Xs = np.vstack((ghost_X, halton_X))\n",
    "    initial_ys = np.hstack((ghost_y, halton_y))\n",
    "\n",
    "    # count number of ghost points and initial points\n",
    "    num_initial_points = len(initial_ys)\n",
    "    num_ghost_points = len(ghost_y)\n",
    "\n",
    "    model, likelihood, X, y, rmse_list, entropy_list, posterior_list, _ = sample_and_train_gp(\n",
    "        cs,\n",
    "        grid,\n",
    "        xx,\n",
    "        yy,\n",
    "        sampling_strategy= sampling_strategy,\n",
    "        mean_module_name=mean_module,\n",
    "        psi_sigma=psi_sigma,\n",
    "        sigmoid_type=sigmoid_type,\n",
    "        psi_gamma=psi_gamma,\n",
    "        psi_lambda=psi_lambda,\n",
    "        lr=learning_rate,\n",
    "        num_initial_training_iters=num_initial_points_training_iters,\n",
    "        num_new_points_training_iters=num_new_points_training_iters,\n",
    "        num_new_points=num_new_points,\n",
    "        beta_for_regularization=beta_for_regularization,\n",
    "        train_on_all_points_after_sampling=train_on_all_points_after_sampling,\n",
    "        phi=normalize_to_unit_range,\n",
    "        print_training_hyperparameters=print_training_hyperparameters,\n",
    "        print_training_iters=print_training_iters,\n",
    "        progress_bar=print_progress_bar,\n",
    "        min_lengthscale=min_lengthscale,\n",
    "        calculate_rmse=plot_b_rmse,\n",
    "        calculate_entropy=calculate_entropy,\n",
    "        calculate_posterior=calculate_posterior,\n",
    "        initial_Xs=initial_Xs,\n",
    "        initial_ys=initial_ys,\n",
    "        num_ghost_points=num_ghost_points,\n",
    "    )\n",
    "\n",
    "    #################\n",
    "    # EVALUATE GRID #\n",
    "    #################\n",
    "\n",
    "    # transform evaluation grid so it can be used by GP\n",
    "    grid_transformed = transform_dataset(grid, phi=normalize_to_unit_range)\n",
    "\n",
    "    # get the predictions on the eval grid\n",
    "    zz = evaluate_posterior_mean(model, likelihood, grid_transformed).reshape(xx.shape)\n",
    "\n",
    "    results[i] = {\n",
    "        'xx': xx,\n",
    "        'yy': yy,\n",
    "        'zz': zz,\n",
    "        'X': X,\n",
    "        'y': y,\n",
    "        'left': left,\n",
    "        'right': right,\n",
    "        'top': top,\n",
    "        'bottom': bottom,\n",
    "        'cs': cs,\n",
    "        'psi_sigma': psi_sigma,\n",
    "        'sigmoid_type': sigmoid_type,\n",
    "        'psi_gamma': psi_gamma,\n",
    "        'psi_lambda': psi_lambda,\n",
    "        'x_min': x_min,\n",
    "        'x_max': x_max,\n",
    "        'y_min': y_min,\n",
    "        'y_max': y_max,\n",
    "        'xs': xs,\n",
    "        'ys': ys,\n",
    "        'entropy_list': entropy_list,\n",
    "        'initial_points': num_initial_points,\n",
    "        'grid': grid,\n",
    "        'model': model,\n",
    "        'likelihood': likelihood,\n",
    "        'f': normalize_to_unit_range,\n",
    "        'rmse': rmse_list,\n",
    "        'posterior_list': posterior_list,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec8ce2",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55425aed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "rmse_values = []\n",
    "\n",
    "# Create a figure and define the grid\n",
    "fig = plt.figure(figsize=(figure_width, figure_height), dpi=dpival)\n",
    "gs = GridSpec(num_plot_rows, num_plot_columns, width_ratios=[4, 2.5]) \n",
    "\n",
    "for i in range(len(phenos)):\n",
    "\n",
    "    ############\n",
    "    # PLOTTING #\n",
    "    ############\n",
    "    \n",
    "    title, _ = phenos[i]\n",
    "    \n",
    "    pheno_results_dict = results[i]\n",
    "    \n",
    "    xx = pheno_results_dict['xx']\n",
    "    yy = pheno_results_dict['yy']\n",
    "    zz = pheno_results_dict['zz']\n",
    "    X = pheno_results_dict['X']\n",
    "    y = pheno_results_dict['y']\n",
    "    left = pheno_results_dict['left']\n",
    "    right = pheno_results_dict['right']\n",
    "    top = pheno_results_dict['top']\n",
    "    bottom = pheno_results_dict['bottom']\n",
    "    cs = pheno_results_dict['cs']\n",
    "    psi_sigma = pheno_results_dict['psi_sigma']\n",
    "    psi_gamma = pheno_results_dict['psi_gamma']\n",
    "    psi_lambda = pheno_results_dict['psi_lambda']\n",
    "    x_min = pheno_results_dict['x_min']\n",
    "    x_max = pheno_results_dict['x_max']\n",
    "    y_min = pheno_results_dict['y_min']\n",
    "    y_max = pheno_results_dict['y_max']\n",
    "    xs = pheno_results_dict['xs']\n",
    "    ys = pheno_results_dict['ys']\n",
    "    entropy_list = pheno_results_dict['entropy_list']\n",
    "    initial_points = pheno_results_dict['initial_points']\n",
    "    grid = pheno_results_dict['grid']\n",
    "    f = pheno_results_dict['f']\n",
    "    posterior_list = pheno_results_dict['posterior_list']\n",
    "    rmse_list = pheno_results_dict['rmse']\n",
    "    \n",
    "    print(rmse_list[-1])\n",
    "    rmse = rmse_list[-1]\n",
    "    \n",
    "    rmse_values.append(f'{title}: ' + str(rmse_list[-1]))\n",
    "    \n",
    "    model = posterior_list[-1][0]\n",
    "    likelihood = posterior_list[-1][1]\n",
    "    zz = evaluate_posterior_mean(model, likelihood, grid_transformed).reshape(xx.shape)\n",
    "    \n",
    "    # MAKE PLOT A\n",
    "    ax1 = plt.subplot(gs[0:num_plot_rows, 0])  # Span all rows in the first column\n",
    "\n",
    "\n",
    "    # plot the contour field\n",
    "    if plot_a_prior:\n",
    "        plt.pcolormesh(xx, yy, zz, cmap=a_prior_color_gradient, vmin=a_prior_grad_min, \n",
    "                       vmax=a_prior_grad_max, zorder = posterior_zorder)\n",
    "        cbar = plt.colorbar(pad=fig_a_cb_pad) \n",
    "        cbar.set_ticks(fig_a_cb_ticks)\n",
    "        cbar.set_ticklabels(fig_a_cb_labs)\n",
    "        cbar.set_label(fig_a_cb_label, labelpad=fig_a_cb_label_pad)\n",
    "\n",
    "    # plot the training data\n",
    "    if plot_a_data:\n",
    "        x1_failure = X[y == 0, 0].reshape(-1)\n",
    "        x2_failure = X[y == 0, 1].reshape(-1)\n",
    "        x1_success = X[y == 1, 0].reshape(-1)\n",
    "        x2_success = X[y == 1, 1].reshape(-1)\n",
    "        # Create diamond corner array\n",
    "        diamond_corners = np.array([\n",
    "                                  [x1_failure, x2_failure + diamond_height*diamond_size],\n",
    "                                  [x1_failure + diamond_width*diamond_size, x2_failure],\n",
    "                                  [x1_failure, x2_failure - diamond_height*diamond_size],\n",
    "                                  [x1_failure - diamond_width*diamond_size, x2_failure]])\n",
    "        plt.scatter(x1_success, x2_success, marker =success_marker, s=marker_size, color=success_color, \n",
    "                    linewidth=plus_line_width, zorder=success_zorder, label=success_label)\n",
    "        plt.fill(diamond_corners[:, 0], diamond_corners[:, 1], color= diamond_fill_color, edgecolor=failure_color, \n",
    "                 linewidth=diamond_line_width, zorder= fail_zorder, label = failure_label)\n",
    "\n",
    "        \n",
    "\n",
    "    # plot the canonical CSF\n",
    "    if plot_a_canon:\n",
    "        latent_x1 = np.linspace(left, x_max, num_curve_points)\n",
    "        latent_x2 = cs(latent_x1)\n",
    "        plt.plot(latent_x1, latent_x2, color=a_latent_color, zorder = canon_zorder)\n",
    "\n",
    "    # plot the level curve\n",
    "    if plot_a_thresh:\n",
    "        level = (1 - psi_lambda + psi_gamma) / 2\n",
    "        CS = plt.contour(xx, yy, zz, levels=[level], colors=a_mean_color,\n",
    "                    linestyles=a_linestyle, zorder=thresh_zorder)\n",
    "        \n",
    "        for c in CS.collections:\n",
    "            c.set_dashes(a_dash_list)\n",
    "\n",
    "    # add xticks and yticks and fit to grid\n",
    "    plt.xticks(xticks_values, xticks_labels)\n",
    "    plt.yticks(yticks_values, yticks_labels)\n",
    "    x_padding = (x_max - x_min) / (2 * (xs - 1))\n",
    "    y_padding = (y_max - y_min) / (2 * (ys - 1))\n",
    "    plt.xlim(x_min - x_padding, x_max + x_padding)\n",
    "    plt.ylim(y_min - y_padding, y_max + y_padding)\n",
    "\n",
    "    # title and axis labels\n",
    "    plt.title(a_title, fontsize = title_font_size)\n",
    "    plt.xlabel(a_xlab, fontsize = label_font_size)\n",
    "    plt.ylabel(a_ylab, fontsize = label_font_size)\n",
    "\n",
    "    \n",
    "    # MAKE PLOT B\n",
    "    \n",
    "    ax2 = plt.subplot(gs[0:math.floor(num_plot_rows/2), 1])  # Occupy the first and second row in the second column\n",
    "    \n",
    "    # plot the spline\n",
    "    if plot_b_canon:\n",
    "        latent_x1 = np.linspace(left, x_max, num_curve_points)\n",
    "        latent_x2 = cs(latent_x1)\n",
    "        plt.plot(latent_x1, latent_x2, color=b_latent_color)\n",
    "\n",
    "    # plot the level curve\n",
    "    if plot_b_thresh:\n",
    "        level = (1 - psi_lambda + psi_gamma) / 2\n",
    "        CS = plt.contour(xx, yy, zz, levels=[level], color=b_mean_color)\n",
    "        for c in CS.collections:\n",
    "            c.set_dashes(b_dash_list)\n",
    "            c.set_edgecolor(b_mean_color)\n",
    "\n",
    "    # set xticks and yticks and fit to the grid\n",
    "    plt.xticks(xticks_values, xticks_labels)\n",
    "    plt.yticks(yticks_values, yticks_labels)\n",
    "    x_padding = (x_max - x_min) / (2 * (xs - 1))\n",
    "    y_padding = (y_max - y_min) / (2 * (ys - 1))\n",
    "    plt.xlim(x_min - x_padding, x_max + x_padding)\n",
    "    plt.ylim(y_min - y_padding, y_max + y_padding)\n",
    "\n",
    "    # title, axis labels and legend\n",
    "    plt.title(b_title, fontsize= title_font_size)\n",
    "    plt.xlabel(b_xlab, fontsize = label_font_size)\n",
    "    plt.ylabel(b_ylab, fontsize = label_font_size)\n",
    "    latent = mlines.Line2D([], [], color=b_latent_color, label=latent_label)\n",
    "    mean = mlines.Line2D([], [], color=b_mean_color, dashes=b_dash_tuple, label=mean_label)\n",
    "    plt.legend(loc=b_legend_location, fontsize=legend_font_size, handles=[latent, mean], frameon=False)\n",
    "\n",
    "    \n",
    "    # MAKE PLOT C\n",
    "    \n",
    "    ax3 = plt.subplot(gs[math.ceil(num_plot_rows/2):num_plot_rows, 1])  # Occupy the last 2 rows in the second column\n",
    "\n",
    "     # create the data set to evaluate\n",
    "    log_freqs = np.full(num_curve_points, freq_to_slice_at)\n",
    "    log_contrasts = np.linspace(y_min, y_max, num_curve_points)\n",
    "\n",
    "\n",
    "    # plot true (simulated) outputs\n",
    "    if plot_c_canonical:\n",
    "        sim_outputs = simulate_sigmoid(log_freqs, log_contrasts, cs, psi_gamma, psi_lambda, sigmoid_type = sigmoid_type, psi_sigma = psi_sigma)    \n",
    "         #plot them\n",
    "        plt.plot(log_contrasts, sim_outputs, color=c_latent_color)\n",
    "\n",
    "    \n",
    "    # plot cdf predicted by GP\n",
    "    if plot_c_cdf:\n",
    "        D = np.vstack((log_freqs, log_contrasts)).T\n",
    "        Dt = transform_dataset(D, phi=f)\n",
    "        # get the predictions on D\n",
    "        GP_outputs = evaluate_posterior_mean(model, likelihood, Dt)\n",
    "        plt.plot(log_contrasts, GP_outputs, color=c_mean_color, linestyle=c_dash_symbol, dashes=c_dash)\n",
    "    \n",
    "    ###########\n",
    "    # GENERAL #\n",
    "    ###########\n",
    "\n",
    "    # A, B, and C labels for each subplot\n",
    "    fig.text(*a_subplot_coords, \"A\", fontsize=subplot_label_font_size)\n",
    "    fig.text(*b_subplot_coords, \"B\", fontsize=subplot_label_font_size)\n",
    "    fig.text(*c_subplot_coords, \"C\", fontsize=subplot_label_font_size)\n",
    "\n",
    "    # Set xticks, yticks and limits\n",
    "    plt.xticks(c_xticks_values, c_xticks_labels)\n",
    "    plt.yticks(c_yticks_values, c_yticks_labels)\n",
    "    plt.tick_params(**axis_tick_params)\n",
    "    \n",
    "    plt.xlim(y_min, y_max) # y_lim is for contrast, and here contrast is on the x-axis\n",
    "    plt.ylim(0, 1) # 0 to 1 for probability\n",
    "    \n",
    "    # title, axist labels and legend\n",
    "    plt.title(c_title, fontsize = title_font_size)\n",
    "    plt.xlabel(c_xlab, fontsize = label_font_size)\n",
    "    plt.ylabel(c_ylab, fontsize = label_font_size)\n",
    "    plt.legend(loc=c_legend_location, fontsize=legend_font_size, handles=[latent, mean], frameon=False)\n",
    "    \n",
    "        # Save fit quality\n",
    "    if (save_mode and save_rmse):\n",
    "        ensure_directory_exists(save_dir)\n",
    "        filename = rmse_txt_path\n",
    "        with open(filename, 'w') as file:\n",
    "            for string in rmse_values:\n",
    "                file.write(string + '\\n')\n",
    "    \n",
    "# Show and/or save figure \n",
    "if save_mode:\n",
    "    ensure_directory_exists(save_dir)\n",
    "    plt.savefig(a_png_path, bbox_inches='tight', dpi=dpival)\n",
    "    plt.savefig(a_pdf_path, bbox_inches='tight', dpi=dpival)\n",
    "if scrn_mode:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7234e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
